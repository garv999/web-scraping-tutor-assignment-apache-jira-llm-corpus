# Apache Jira Scraper

A lightweight, fault-tolerant **CLI tool** to fetch and transform public issue data from **Apacheâ€™s Jira instance** into structured **JSONL files** for analysis or model-ready datasets.

---

## ğŸ” Overview

The scraper collects issues, comments, and metadata from **Apache Kafka**, **Spark**, and **Hadoop**, handling retries, pagination, and malformed data gracefully.  
Results are persisted to **Supabase** and exported as clean **JSONL corpora** for multiple task types â€” perfect for LLM fine-tuning or analytics.

---

## âš™ï¸ Quick Start

```bash
# 1. Install dependencies
npm install

# 2. Add Supabase credentials (optional)
VITE_SUPABASE_URL=https://<supabase>.supabase.co
VITE_SUPABASE_ANON_KEY=<anon-key>

# 3. Run a short scrape
node src/cli.js scrape --max-issues=5

# 4. Export structured data
node src/cli.js export KAFKA --output-dir=./output

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚      CLI Interface(src/cli.js)         â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚            Jira API Client(jira-client.js)           â”‚
       â”‚                - Rate limiting                       â”‚
       â”‚                - Retry logic, Error handling         â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚           Scraper Service(scraper.js)                â”‚
       â”‚  - SQLite checkpoint with resumable offsets          â”‚
       â”‚  - Batch processing and State checkpointing          â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚         Text Formatter(text-formatter.js)            â”‚
       â”‚  - JSONL generation                                  â”‚
       â”‚  - Task creation(Summarization, Classification, Q&A) â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                    Output Files                      â”‚
       â”‚                  (*.jsonl + stats)                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```
## ğŸ§© Core Components

| Module | Responsibility |
|:--------|:----------------|
| `jira-client.js` | Jira REST API wrapper with rate limiting, retries, and pagination |
| `scraper.js` | Batch scraping and checkpointing for resumability |
| `database.js` | Supabase persistence and upsert logic |
| `text-formatter.js` | Transforms raw data into structured JSONL training tasks |

---

## ğŸ“„ Output Format

Each `.jsonl` line = one structured training record with metadata and task type.

### **Supported Task Types**
- ğŸ“ **Summarization** â€“ summarize issue descriptions  
- ğŸ·ï¸ **Classification** â€“ identify issue type & priority  
- ğŸ’¬ **Q&A** â€“ generate questionâ€“answer pairs from issue context  
- ğŸ§  **Discussion Analysis** â€“ extract insights from threaded comments  
- âš™ï¸ **Key Extraction** â€“ extract technical entities and keywords  

### **Example Output Structure**
output/
â”œâ”€â”€ kafka_training.jsonl
â”œâ”€â”€ spark_training.jsonl
â””â”€â”€ hadoop_training.jsonl


---

## ğŸ›¡ï¸ Reliability & Edge Handling

- âœ… Retries on 429 / 5xx with **exponential backoff**
- ğŸ’¾ **State checkpointing** for resumable scrapes
- ğŸ§© **Recursive ADF text extraction**
- â™»ï¸ **Idempotent DB writes** (upsert by issue key)
- ğŸ§¯ **Graceful handling** of null / malformed data

---

## âš¡ Optimizations

- ğŸš€ Request batching (**50 issues per call**)
- â±ï¸ Rate-limited queue (**10 req/s**)
- ğŸ“„ Streaming JSONL export (**low memory footprint**)
- ğŸ” Incremental processing with saved scraper state

---

## ğŸ§± Tech Stack

- **Node.js** 18+  
- **Axios**, **p-queue**, **p-retry**  
- **Supabase** (PostgreSQL backend)  
- **JSONL** for efficient, streamable dataset export  

---

## ğŸ§­ Future Improvements

- ğŸ§µ Distributed scraping via **Redis queue**  
- ğŸ•’ Incremental updates using `updated_since` filter  
- â˜ï¸ Export formats: **Parquet**, **CSV**, **S3 upload**

---

## ğŸ“œ License

**MIT License**

---
